{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "For each WormBase id find the genomic_position\n",
    "and write the 2,000 nucleotides before the genomic start position\n",
    "\n",
    "Note: that the start may be directionally dependent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Download Gene IDs from Wormbase\n",
    "wormbase_version=\"WS293\"\n",
    "output_dir=\"./output\"\n",
    "base_url=\"https://downloads.wormbase.org/releases/${wormbase_version}/species/c_elegans/PRJNA13758\"\n",
    "gene_ids=\"c_elegans.PRJNA13758.${wormbase_version}.geneIDs.txt.gz\"\n",
    "wget -nv -P \"${output_dir}\" \"${base_url}/annotation/${gene_ids}\"\n",
    "gunzip --force ${output_dir}/${gene_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create GeneIDs.csv from the downloaded txt file\n",
    "wormbase_version=\"WS293\"\n",
    "output_dir=\"./output\"\n",
    "gene_ids=\"c_elegans.PRJNA13758.${wormbase_version}.geneIDs\"\n",
    "\n",
    "gene_ids_txt=\"${output_dir}/${gene_ids}.txt\"\n",
    "gene_ids_csv=\"${output_dir}/${gene_ids}.csv\"\n",
    "\n",
    "awk -F',' '$5==\"Live\" {print $2\",\"$3\",\"$4\",\"$6}' \"$gene_ids_txt\" > \"$gene_ids_csv\"\n",
    "awk 'BEGIN {print \"Wormbase_Id,Gene_name,Sequence_id,Gene_Type\"} 1' \"${gene_ids_csv}\" > temp && mv temp \"${gene_ids_csv}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic Position Data Retrieval Script\n",
    "-----------\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "Retrieves genomic position data for C. elegans genes from Wormbase API.\n",
    "\n",
    "\n",
    "### Functionality\n",
    "\n",
    "This script:\n",
    "\n",
    "* Reads a CSV file containing Wormbase gene IDs\n",
    "* Queries the Wormbase API for genomic position data (chromosome, start position, stop position) for each gene\n",
    "* Writes the results to a new CSV file\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* Wormbase API access\n",
    "* Input CSV file containing Wormbase gene IDs: `./output/c_elegans.PRJNA13758.WS293.geneIDs.csv`\n",
    "* Output CSV file for genomic position data: `./output/genomic_position.csv`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Add pub_worm directory to the Python path\n",
    "sys.path.append(\"/Users/dan/Code/Python/pub_worm\")\n",
    "from pub_worm.wormbase.wormbase_api import WormbaseAPI\n",
    "from pub_worm.ensembl.ensembl_api import get_sequence_region, create_fasta\n",
    "\n",
    "wormbase_version=\"WS293\"\n",
    "gene_ids_csv = f\"./output/c_elegans.PRJNA13758.{wormbase_version}.geneIDs.csv\"\n",
    "\n",
    "\n",
    "wormbase_api = WormbaseAPI(\"field\", \"gene\", \"genomic_position\")\n",
    "gene_ids_df = pd.read_csv(gene_ids_csv)\n",
    "\n",
    "results = []\n",
    "total_ids = len(gene_ids_df['Wormbase_Id'])\n",
    "\n",
    "for idx, wormbase_id in enumerate(gene_ids_df['Wormbase_Id']):\n",
    "    wormbase_data_result = wormbase_api.get_wormbase_data(wormbase_id)\n",
    "    if \"genomic_position\" in wormbase_data_result:\n",
    "        chromosome = wormbase_data_result[\"genomic_position\"][\"seqname\"]\n",
    "        start_pos = wormbase_data_result[\"genomic_position\"][\"start\"]\n",
    "        stop_pos = wormbase_data_result[\"genomic_position\"][\"stop\"]\n",
    "    else:\n",
    "        print(f\"NO genomic_position for {wormbase_id}\")\n",
    "    results.append((wormbase_id,chromosome,start_pos,stop_pos))\n",
    "    \n",
    "    # Print a progress update every 50 iterations\n",
    "    if (idx + 1) % 50 == 0 or (idx + 1) == total_ids:  # Also print for the final iteration\n",
    "        print(f\"Processed {idx + 1} Wormbase IDs of {total_ids}\")\n",
    "\n",
    "    \n",
    "df_results = pd.DataFrame(results, columns=['Wormbase_Id', 'Chromosome', 'Start_Pos', 'Stop_Pos'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_results.to_csv('./output/genomic_position.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieves genomic sequences for promoter regions\n",
    "---------------\n",
    "\n",
    "### Overview\n",
    "\n",
    "Retrieves genomic sequences for promoter regions of given WormBase IDs using the Ensembl API.\n",
    "\n",
    "### Functionality\n",
    "\n",
    "This script:\n",
    "\n",
    "* Reads a CSV file containing WormBase IDs, chromosome numbers, and genomic positions.\n",
    "* Adjusts positions to extract 2000 bp promoter regions (upstream or downstream).\n",
    "* Uses asyncio to fetch sequences from Ensembl API in parallel.\n",
    "* Divides the input DataFrame into chunks and processes them concurrently using a ProcessPoolExecutor.\n",
    "* Combines results and saves them to a new CSV file containing WormBase IDs and corresponding genomic sequences.\n",
    "\n",
    "### Additional Requirements\n",
    "\n",
    "* This code does not run in the Notebook do to limitation with Jupyter\n",
    "* Use not_a_notebook.py as Jupyter can not run this code!!\n",
    "* python -u \"/Users/dan/Code/Python/pub_worm/notebooks/not_a_notebook.py\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "Use not_a_notebook.py as Jupyter can not run this code!!\n",
    "python -u \"/Users/dan/Code/Python/pub_worm/notebooks/not_a_notebook.py\"\n",
    "=========================================================\n",
    "# import os\n",
    "# import sys\n",
    "# import pandas as pd\n",
    "# import asyncio\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# import multiprocessing\n",
    "\n",
    "# sys.path.append(\"/Users/dan/Code/Python/pub_worm\")\n",
    "# from pub_worm.ensembl.ensembl_api import async_get_sequence_region, async_create_fasta\n",
    "\n",
    "# def get_promoter_region(start_pos, stop_pos):\n",
    "#     if start_pos > stop_pos:\n",
    "#         print(\"3 prime\")\n",
    "#         return stop_pos + 1, stop_pos + 2001\n",
    "#     elif stop_pos > start_pos:\n",
    "#         # Return Start_Pos-2001, Start_Pos-1\n",
    "#         #print(\"5 prime\")\n",
    "#         return start_pos - 2001, start_pos - 1\n",
    "#     else:\n",
    "#         # Handle the case where Start_Pos == Stop_Pos (optional)\n",
    "#         raise ValueError(\"Start_Pos and Stop_Pos are equal, cannot adjust positions.\")\n",
    "\n",
    "\n",
    "# def run_async_get_sequence(promoter_start, promoter_stop, chromosome):\n",
    "#     return asyncio.run(async_get_sequence_region(promoter_start, promoter_stop, chromosome))\n",
    "\n",
    "# # Function to process a chunk of the DataFrame\n",
    "# def process_chunk(chunk):\n",
    "#     results = []\n",
    "#     process_id = os.getpid() \n",
    "#     total_ids = len(chunk)\n",
    "#     for idx, row in enumerate(chunk.itertuples()):\n",
    "#         wormbase_id = row.Wormbase_Id\n",
    "#         chromosome = row.Chromosome\n",
    "#         start_pos = row.Start_Pos\n",
    "#         stop_pos = row.Stop_Pos\n",
    "        \n",
    "#         promoter_start, promoter_stop = get_promoter_region(start_pos, stop_pos)\n",
    "#         sequence = run_async_get_sequence(promoter_start, promoter_stop, chromosome)\n",
    "#         if sequence:\n",
    "#             results.append((wormbase_id,sequence))\n",
    "#         else:\n",
    "#             print(f\"NO genomic_sequence for {wormbase_id}\")\n",
    "    \n",
    "#         if (idx + 1) % 100 == 0 or (idx + 1) == total_ids:  # Also print for the final iteration\n",
    "#             print(f\"Processed {idx + 1} Wormbase IDs from process {process_id}\")\n",
    "        \n",
    "#     return results\n",
    "\n",
    "# # Function to divide DataFrame into chunks of 5000 rows\n",
    "# def divide_into_chunks(df, chunk_size=5000):\n",
    "#     for i in range(0, len(df), chunk_size):\n",
    "#         yield df[i:i + chunk_size]\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     genomic_position_df = pd.read_csv(\"./output/genomic_position.csv\")\n",
    "\n",
    "#     # Divide the DataFrame into chunks of 5000 rows\n",
    "#     chunks = list(divide_into_chunks(genomic_position_df, chunk_size=5000))\n",
    "\n",
    "#     # Create a process pool with 10 processes\n",
    "#     num_processes = min(10, multiprocessing.cpu_count())\n",
    "\n",
    "#     with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "#         # Run each chunk in parallel\n",
    "#         futures = [executor.submit(process_chunk, chunk) for chunk in chunks]\n",
    "\n",
    "#         # Gather the results\n",
    "#         results = []\n",
    "#         for future in futures:\n",
    "#             results.extend(future.result())\n",
    "\n",
    "#     df_results = pd.DataFrame(results, columns=['Wormbase_Id', 'Sequence'])\n",
    "#     df_results.to_csv('./output/genomic_sequences.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convert PFM file to a PWM Dictionary\n",
    "---------------\n",
    "\n",
    "### Overview\n",
    "\n",
    "Convert Position Frequency Matrix (PFM) file to a Position Weight Matrix (PWM) Dictionary\n",
    "\n",
    "### Functionality\n",
    "\n",
    "This script:\n",
    "\n",
    "* Reads a CSV file containing PFM downloaded from https://jaspar.elixir.no/.\n",
    "* Use BioPython to convert PFM to PWD.\n",
    "* Create a Dictionary for down stream use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "import io\n",
    "\n",
    "def read_pwm_file(file_path):\n",
    "    pwm_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        pwm_key = None\n",
    "        pfm_data = \"\"\n",
    "\n",
    "        for line in file:\n",
    "            # Check if the line starts with '>'\n",
    "            if line.startswith('>'):\n",
    "                # If we already have a key and a matrix, process the previous one\n",
    "                if pwm_key is not None and pfm_data:\n",
    "                    pwm_dict[pwm_key] = convert_pfm_to_pwm(pfm_data)\n",
    "                # Start a new PWM entry\n",
    "                pwm_key = line.strip()[1:]  # Remove the '>' character\n",
    "                pfm_data = \"\"  # Reset matrix for the new PWM\n",
    "            else:\n",
    "                pfm_data += line\n",
    "\n",
    "        # Don't forget to process the last PWM matrix\n",
    "        if pwm_key is not None and pfm_data:\n",
    "            pwm_dict[pwm_key] = convert_pfm_to_pwm(pfm_data)\n",
    "\n",
    "    return pwm_dict\n",
    "\n",
    "def convert_pfm_to_pwm(pfm_data):\n",
    "    pfm_file = io.StringIO(pfm_data)\n",
    "    pwm = motifs.read(pfm_file, \"pfm\")\n",
    "    pwm = pwm.counts.normalize(pseudocounts=0.1)  # Add pseudocounts to avoid division by zero\n",
    "    pwm = pwm.log_odds()\n",
    "    return pwm\n",
    "\n",
    "# Example usage\n",
    "file_path = './output/JASPAR2024_combined_matrices_1248851_pfm.txt'\n",
    "file_path = \"./output/MA2156.1.xbp-1.pfm\"\n",
    "\n",
    "pwm_dict = read_pwm_file(file_path)\n",
    "\n",
    "# Print the PWM for a particular motif\n",
    "print(f\"{len(pwm_dict)}\")\n",
    "\n",
    "for key, pwm in pwm_dict.items():\n",
    "    print(f'Motif: {key}\\nPWM:\\n{pwm}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scan the sequence for motif matches\n",
    "\n",
    "def search_promoter_sequence(pwm_dict, promoter_sequence_str):\n",
    "    promoter_sequence = Seq(promoter_sequence_str)\n",
    "    found_keys={}\n",
    "    for key, pwm in pwm_dict.items():\n",
    "        matches = pwm.search(promoter_sequence)\n",
    "        for match in matches:\n",
    "            if key in found_keys:\n",
    "                found_keys[key].append(matches)\n",
    "            else:\n",
    "                found_keys[key] = [matches]\n",
    "    return found_keys\n",
    " \n",
    "\n",
    "\n",
    "promoter_sequence_str = \"AAGCATCACCGGAAGAACAACGAACTGTAAGTGAGATTATTTTAACAAATTTCCCGGCTTAAAACGTTTACAATTCTAACTTCTTTTTTTAGATAATGGAAGGCCTTGGTCATGTACATCGTCTTCAATGCACTCACCTAATTGAGAATAGCACACTGATTCCTAAACTACAAGAAATTAAATTTGACTTTGCAATTCATGAAGTATTCGATTCTTGTGGAGTCGGTATTCTTGAGGTAATCGGTGTACAGAAGACTGTTATTGTATCATCAACTGGACCAATGGATGTTGTCCCAATTACACTTGGAATATCTGATACATTGAACACTCCATGTTAGTTTGACACAGAATGGAAATGATTTACTATGAAACCAATTTCAGCTCTATTATCGGATTATGGAAGTTACCTATCATTTTTTGAAAAACGAAGAAATCTCAAGTTTCTATCTGGAATGCTCAATTTCCACGAAATGCAGGACTCAATGATATCTCCGCTTTTCAAAAAATATTATGGATTGAAAAAACCTACTGGTGAAATAATGAGACAAGCAAATTTATTGTTTTATAATATTCATGAAGGATCAGATGGAATGAGAATGAGAGGACGAAGAAGTTTTGATATTGGAGGGATTGCTTTTAAGGATCAAAAGAATTTGACTATGGTATTTTGCCTTTTTGCAAATTTTTTGAATAGCGCCTGAAGCAGTTTGCAAGCTTTACAATAAGATTATGGTGGTATTGATTTTTAATTCAGGAGTATCAAACTCTTCTCTCTGATCCTCGTCCTAAAGTGCTCGTATCATTTGGTACTGCAGCCACATCATCTCATATGCCTCAAAATTTGAAAAATTCGTTGATGACTGCAATGAAACAAATGAACAATGTTTTGTTCATATGGAAATATGAAATGGAAGATAATTTCACAAAACAGGAGGAGCTCACAACAAATATAATTTTCAAAAAGTTTTTGCCGCAGACTGATTTATTAGGTGAGTGATTT\"\n",
    "found_keys = search_promoter_sequence(pwm_dict, promoter_sequence_str)  \n",
    "print(len(found_keys))\n",
    "for found_key in found_keys:   \n",
    "    print(f\"Motif {found_key} found matches {len(found_keys[found_key])}\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "import io\n",
    "\n",
    "genomic_sequences_1000_df = pd.read_csv(\"./output/genomic_sequences_1000.csv\")\n",
    "pwm_dict = read_pwm_file(\"./output/MA2156.1.xbp-1.pfm\")\n",
    "\n",
    "top_genes=[\"WBGene00002016\", \"WBGene00002017\", \"WBGene00002019\", \"WBGene00022382\", \"WBGene00002021\", \"WBGene00002015\", \"WBGene00000214\", \"WBGene00010470\", \n",
    "           \"WBGene00012683\", \"WBGene00000215\", \"WBGene00002018\", \"WBGene00009430\", \"WBGene00000217\", \"WBGene00006533\", \"WBGene00006959\", \"WBGene00015756\", \n",
    "           \"WBGene00008850\", \"WBGene00021979\", \"WBGene00013035\", \"WBGene00015913\", \"WBGene00001091\", \"WBGene00003903\", \"WBGene00004438\", \"WBGene00019068\"]\n",
    "\n",
    "\n",
    "for top_gene in top_genes: \n",
    "    top_gene_row = genomic_sequences_1000_df[genomic_sequences_1000_df['Wormbase_Id'] == top_gene]\n",
    "    #sequence_str = ' '.join(top_gene['Sequence'].astype(str))\n",
    "    sequence_str = top_gene_row['Sequence'].iloc[0]\n",
    "    wormbase_id_str = top_gene_row['Wormbase_Id'].iloc[0]\n",
    "\n",
    "    found_keys = search_promoter_sequence(pwm_dict, sequence_str)  \n",
    "\n",
    "    for found_key in found_keys:   \n",
    "        print(f\"{wormbase_id_str} found matches {len(found_keys[found_key])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wormbase_version=\"WS293\"\n",
    "gene_ids_csv = f\"./output/c_elegans.PRJNA13758.{wormbase_version}.geneIDs.csv\"\n",
    "gene_ids_df = pd.read_csv(gene_ids_csv)\n",
    "top_30_down_df = pd.read_csv(\"./output/top_30_down.csv\", header=None, names=['Wormbase_Id'])\n",
    "merged_df = top_30_down_df.merge(gene_ids_df, how='left', left_on='Wormbase_Id', right_on='Wormbase_Id')\n",
    "merged_df[['Gene_name','Wormbase_Id']].to_csv('./output/top_30_down_seq.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
