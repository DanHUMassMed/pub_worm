{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Programs Integated with Pub_worm\n",
    "\n",
    "* Look at external programs and use pub_worm to solve problems\n",
    "* Look at BioPythons use and API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import Entrez\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Entrez.api_key = api_key = os.environ.get('NCBI_API_KEY', None)\n",
    "Entrez.email = \"daniel.higgins@yahoo.com\"\n",
    "\n",
    "# Call BioPython get a list of Databases that are managed by NCBI Entrez\n",
    "stream = Entrez.einfo()\n",
    "result = stream.read()\n",
    "stream.close()\n",
    "\n",
    "soup = BeautifulSoup(result, \"xml\")\n",
    "db_name_tags = soup.find_all('DbName')\n",
    "db_names = [db_name_tag.get_text(strip=True) for db_name_tag in db_name_tags]\n",
    "print(db_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Bio Python Entrez to get additional details on the NCBI Databases\n",
    "# NOTE: This seems very slow??\n",
    "for db_name in db_names:\n",
    "    stream = Entrez.einfo(db=db_name)\n",
    "    record = Entrez.read(stream)\n",
    "    print(record)\n",
    "    print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a networkx graph \n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_legend_map(edge_labels):\n",
    "    legend_map={'start_xxx':0}\n",
    "    for value in list(edge_labels.values()):\n",
    "        if value not in legend_map:\n",
    "            max_val = max(list(legend_map.values()))\n",
    "            legend_map[value] = max_val+1\n",
    "    del legend_map['start_xxx']\n",
    "    return legend_map\n",
    "\n",
    "def plot_network_graph(df):\n",
    "\n",
    "    # Create a directed graph\n",
    "    G = nx.from_pandas_edgelist(df, 'source', 'target', edge_attr='edge', create_using=nx.Graph())\n",
    "\n",
    "    # Draw the network diagram with a larger figure size\n",
    "    plt.figure(figsize=(40, 20))  # Set the figure size to 12x8 inches\n",
    "    pos = nx.spring_layout(G)  # positions for all nodes\n",
    "    nx.draw(G, pos, with_labels=True, node_size=4000, node_color='skyblue', font_size=9, font_color='black', edge_color='gray', linewidths=0.5, arrows=False)\n",
    "\n",
    "    # Add edge labels\n",
    "    edge_labels = nx.get_edge_attributes(G, 'edge')\n",
    "    print(type(edge_labels))\n",
    "    # print(edge_labels)\n",
    "    # legend_map = build_legend_map(edge_labels)\n",
    "    # edge_labels_mapped = {}\n",
    "    # for edge_label in edge_labels:\n",
    "    #     edge_label_value = edge_labels[edge_label]\n",
    "    #     map_value = legend_map[edge_label_value]\n",
    "    #     edge_labels_mapped[edge_label]=map_value\n",
    "    # print(legend_map)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "    # y_pos = 0.0\n",
    "    # for key, value in legend_map.items():\n",
    "    #     plt.text(0.0, y_pos, f\"{value} = {key}\", fontsize=12)\n",
    "    #     y_pos -= 0.1  # Adjust the y position for the next text\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('output/test.csv')\n",
    "edge_names = [\n",
    "    'Phenols',\n",
    "    'Lactones',\n",
    "    'Organic carbonic acids and derivatives',\n",
    "    '6-oxopurines'\n",
    "]\n",
    "selected_rows = df[df['edge'].isin(edge_names)]\n",
    "selected_rows.to_csv(\"output/test1.csv\")\n",
    "plot_network_graph(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "slim_metabolite_df = pd.read_csv(\"output/slim_metabolite.csv\")\n",
    "slim_metabolite_t_df = slim_metabolite_df.T\n",
    "slim_metabolite_t_df.to_csv(\"output/slim_motabolite_t.csv\",index_label='motabolite')\n",
    "slim_metabolite_t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Iterate over each row and create a list of dictionaries\n",
    "list_of_dicts = []\n",
    "for idx, row in slim_metabolite_t_df.iterrows():\n",
    "    cleaned_row = row.dropna().tolist()\n",
    "    row_dict = {str(idx): cleaned_row}\n",
    "    list_of_dicts.append(row_dict)\n",
    "\n",
    "# Print the list of dictionaries\n",
    "print(list_of_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_ignore = ['Chemical entities', 'Hydrocarbon derivatives', 'Organic compounds', 'Organic oxygen compounds', \n",
    "                   'Organooxygen compounds', 'Organic oxides', 'Organic acids and derivatives', 'Organonitrogen compounds', \n",
    "                   'Organopnictogen compounds', 'Organic nitrogen compounds']\n",
    "def shares_edge(source_edge, target):\n",
    "    ret_val=False\n",
    "    target_nm = list(target.keys())[0]\n",
    "    target_edges = target[target_nm]\n",
    "    if source_edge in target_edges:\n",
    "        ret_val = True\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "graph_list = []\n",
    "for index, list_of_dict in enumerate(list_of_dicts):\n",
    "    source_nm = list(list_of_dict.keys())[0]\n",
    "    source_edges  = list_of_dict[source_nm]\n",
    "    #print(f\"{source_nm=} {source_edges=}\")\n",
    "    targets = list_of_dicts[index+1:]\n",
    "    for source_edge in source_edges:\n",
    "        if source_edge not in edges_to_ignore:\n",
    "            for target in targets:\n",
    "                target_nm = list(target.keys())[0]\n",
    "                if shares_edge(source_edge, target):\n",
    "                    graph_list.append({'source':source_nm,'target':target_nm,'edge':source_edge})\n",
    "\n",
    "graph_df = pd.DataFrame(graph_list)\n",
    "graph_df.head()\n",
    "graph_df.to_csv(\"output/test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
