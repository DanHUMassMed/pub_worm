{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntrezAPI imported from: /Users/dan/Code/Python/pub_worm/pub_worm/ncbi/entreze_api.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import inspect\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add a directory to the Python path\n",
    "sys.path.append(\"/Users/dan/Code/Python/pub_worm\")\n",
    "\n",
    "from pub_worm.ncbi.entreze_api import EntrezAPI\n",
    "\n",
    "# Find where EntrezAPI is being load from\n",
    "module = inspect.getmodule(EntrezAPI)\n",
    "if hasattr(module, \"__file__\"):\n",
    "    file_path = module.__file__\n",
    "    print(\"EntrezAPI imported from:\", file_path)\n",
    "else:\n",
    "    print(\"Could not determine the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = {\"Charlie_Serhan\"     :\"Charles N Serhan[au] AND (2019/01/01:2024/04/16[pdat]) AND (harvard[affil])\",\n",
    "            \"Lawrence_Marnett\"   :\"Marnett L[au] AND (2019/01/01:2024/04/16[pdat])AND (vanderbilt[affil])\",\n",
    "            \"Sarah_Fendt\"        :\"Fendt S[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Meng_Wang\"          :\"Meng C Wang[au] AND (2019/01/01:2024/04/16[pdat]) AND (janelia[affil] OR Baylor[affil])\",\n",
    "            \"Jenny_Watts\"        :\"Jennifer L Watts [au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Valerie_Kagan\"      :\"Kagan VE[au] AND (2019/01/01:2024/04/16[pdat])AND (pitt[affil])\",\n",
    "            \"Shirin_Bahmanyar\"   :\"Shirin Bahmanyar[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Arun_Radhakrishnan\" :\"Arun Radhakrishnan[au] AND University of Texas Southwestern[affil] AND(2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Todd_Graham\"        :\"Graham TR[au] AND (2019/01/01:2024/04/16[pdat]) AND (vanderbilt[affil])\",\n",
    "            \"Chris_Burd\"         :\"Burd CG[au] AND (2019/01/01:2024/04/16[pdat])) AND (yale[affil])\",\n",
    "            \"Jeeyun_Chung\"       :\"Jeeyun Chung[au] AND (2019/01/01:2024/04/16[pdat]) AND (harvard[affil])\",\n",
    "            \"Hanaa_Hariri\"       :\"Hanaa Hariri[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Fikadu_Tafesse\"     :\"Tafesse FG[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Roberto_Zoncu\"      :\"Zoncu R[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Kuang_Shen\"         :\"Kuang Shen[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Alison_Ondrus\"      :\"Alison E Ondrus[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Squire_Booker\"      :\"Squire Booker[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Randolph_Hampton\"   :\"Randolph Hampton[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Anne_Spang\"         :\"Anne Spang[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Yasunori_Saheki\"    :\"Yasunori saheki[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Michael_Schlame\"    :\"Michael Schlame[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Brittany_White\"     :\"Brittany M White[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Scott_Hansen\"       :\"Scott D Hansen[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Andre_Nadler\"       :\"Andre Nadler[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Jeffrey_Spraggins\"  :\"Jeffrey Spraggins[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Theodore_Alexandrov\":\"Theodore Alexandrov[au] AND (2019/01/01:2024/04/16[pdat])AND (EMBL[affil])\",\n",
    "            \"Paula_Welander\"     :\"Paula Welander[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Han_Remaut\"         :\"Han Remaut[au] AND (2019/01/01:2024/04/16[pdat])\",\n",
    "            \"Alessio_Accardi\"    :\"Alessio Accardi[au] AND (2019/01/01:2024/04/16[pdat])\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers_for_speaker(search_term):\n",
    "    results = []\n",
    "    esearch_params = {'term': search_term }\n",
    "    ncbi_api = EntrezAPI()\n",
    "    entreze_esearch_data = ncbi_api.entreze_esearch(esearch_params)\n",
    "    if 'WebEnv' in entreze_esearch_data:\n",
    "        results = ncbi_api.entreze_efetch(entreze_esearch_data)\n",
    "    else:\n",
    "        print(\"ERROR: entreze_esearch failed\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie_Serhan\n",
      "Lawrence_Marnett\n",
      "Sarah_Fendt\n",
      "Meng_Wang\n",
      "Jenny_Watts\n",
      "Valerie_Kagan\n",
      "Shirin_Bahmanyar\n",
      "Arun_Radhakrishnan\n",
      "Todd_Graham\n",
      "Chris_Burd\n",
      "Jeeyun_Chung\n",
      "Hanaa_Hariri\n",
      "Fikadu_Tafesse\n",
      "Roberto_Zoncu\n",
      "Kuang_Shen\n",
      "Alison_Ondrus\n",
      "Squire_Booker\n",
      "Randolph_Hampton\n",
      "Anne_Spang\n",
      "Yasunori_Saheki\n",
      "Michael_Schlame\n",
      "Brittany_White\n",
      "Check the format of the http request [Retry: 1] code: 429 Client Error: Too Many Requests for url: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&query_key=1&WebEnv=MCID_66245a3ddd5f115f9b628af1&retmode=xml\n",
      "Scott_Hansen\n",
      "Andre_Nadler\n",
      "Jeffrey_Spraggins\n",
      "Theodore_Alexandrov\n",
      "Paula_Welander\n",
      "Han_Remaut\n",
      "Alessio_Accardi\n"
     ]
    }
   ],
   "source": [
    "papers_for_speakers = {}\n",
    "for speaker in speakers:\n",
    "    search_term = speakers[speaker]\n",
    "    papers_for_speaker = get_papers_for_speaker(search_term)\n",
    "    papers_for_speaker_df = pd.DataFrame(papers_for_speaker)\n",
    "    papers_for_speaker_df['pmid'] = papers_for_speaker_df['pmid'].apply(lambda x: 'https://pubmed.ncbi.nlm.nih.gov/' + x)\n",
    "    papers_for_speaker_df = papers_for_speaker_df.sort_values(by=['impact_factor', 'pub_year'], ascending=[False, False])\n",
    "\n",
    "    papers_for_speakers[speaker]=papers_for_speaker_df\n",
    "    print(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ONE\n",
    "# search_term = \"Charles N Serhan[au] AND (2019/01/01:2024/04/16[pdat]) AND (harvard[affil])\"\n",
    "# papers_for_speaker = get_papers_for_speaker(search_term)\n",
    "# papers_for_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autofit_columns(worksheet):\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column = [cell for cell in column]\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        if max_length > 150:\n",
    "            max_length = 150\n",
    "        adjusted_width = (max_length + 2)  # Adding some extra padding\n",
    "        worksheet.column_dimensions[get_column_letter(column[0].column)].width = adjusted_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "excel_file_path = f\"{output_dir}/articles.xlsx\"\n",
    "\n",
    "if os.path.exists(excel_file_path):\n",
    "    os.remove(excel_file_path)\n",
    "\n",
    "# Create a new workbook\n",
    "workbook = Workbook()\n",
    "\n",
    "# Remove the default \"Sheet\" created by openpyxl\n",
    "default_sheet = workbook['Sheet']\n",
    "#workbook.remove(default_sheet)\n",
    "\n",
    "with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "    #writer.book = workbook\n",
    "    for speaker in sorted(papers_for_speakers.keys()):\n",
    "        df = papers_for_speakers[speaker]\n",
    "        df.to_excel(writer, sheet_name=speaker, index=False)    \n",
    "        \n",
    "    # Autofit and highlight columns for each sheet\n",
    "    for sheet in writer.sheets.values():\n",
    "        autofit_columns(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
