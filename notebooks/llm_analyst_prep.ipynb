{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull the Journal Articles to use in your Research from Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System level imports\n",
    "import sys\n",
    "import asyncio\n",
    "import json\n",
    "sys.path.append('/Users/dan/Code/Python/pub_worm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pub_worm.ncbi.entreze_api import EntrezAPI\n",
    "from pub_worm.wormbase.wormbase_api import WormbaseAPI\n",
    "\n",
    "async def get_pmid_for_wbpid(reference):\n",
    "    wormbase_api = WormbaseAPI(\"field\", \"paper\", \"pmid\")\n",
    "    pmid = wormbase_api.get_wormbase_data(reference['wbp_id'])\n",
    "    return {**reference, **pmid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_unique_wbp_ids(references, unique_references):\n",
    "    \"\"\"\n",
    "    Updates the set of unique wbp_ids with new IDs from the list of references\n",
    "    and returns the list of references that have not been seen before.\n",
    "    \"\"\"\n",
    "    new_references = []\n",
    "    \n",
    "    # Iterate through the references\n",
    "    wbp_ids = set(unique_references.keys())\n",
    "    for ref in references:\n",
    "        wbp_id = ref[\"wbp_id\"]\n",
    "        # If the wbp_id is not in the set, add it to the set and add the reference to the new list\n",
    "        if wbp_id not in wbp_ids:\n",
    "            #print(ref)\n",
    "            unique_references[wbp_id]={'title':ref['wbp_title'], 'abstract':ref.get('wbp_abstract',\"\"),'pmcid':0}\n",
    "            new_references.append(ref)\n",
    "    \n",
    "    return new_references, unique_references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we did not get the full article from pubmed central (PMC) then save the title and abstract from pubmed\n",
    "def pmc_not_found(unique_references):\n",
    "    for unique_reference in unique_references.values():\n",
    "        if unique_reference['pmcid'] == 0:\n",
    "            content = f\"Title:{unique_reference['title']}\\n\"\n",
    "            content += f\"Abstract: {unique_reference['abstract']}\\n\"\n",
    "            content += f\"Content: \\n\"\n",
    "            file_nm = f\"./output/PM{unique_reference['pmid']}.txt\"\n",
    "            with open(file_nm, 'w') as file:\n",
    "                file.write(content)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_references_wbid(wormbase_id, unique_references):\n",
    "    results_file_nm = f\"./output/{wormbase_id}.json\"\n",
    "    print(f\"Processing {wormbase_id}\")\n",
    "    wormbase_api = WormbaseAPI(\"field\", \"gene\", \"references\")\n",
    "    \n",
    "    # 1. Get all the references for the given wormbase_id\n",
    "    wormbase_data = wormbase_api.get_wormbase_data(wormbase_id)\n",
    "    \n",
    "    # 2a. collect only Journal articles\n",
    "    if isinstance(wormbase_data['references_list'], dict):\n",
    "        references = [wormbase_data['references_list']] # Make sure we have a list\n",
    "    else:\n",
    "        references = wormbase_data['references_list']        \n",
    "    journal_articles = [ref for ref in references if ref['wbp_type'] == 'Journal article' ]\n",
    "    \n",
    "    # 2b. collect only articles that we have not seen\n",
    "    journal_articles, unique_references = update_unique_wbp_ids(journal_articles, unique_references)\n",
    "\n",
    "    # 3a. Get the associated Pubmed Ids\n",
    "    pmid_for_wbpid_list = await asyncio.gather(*[get_pmid_for_wbpid(ref) for ref in journal_articles])\n",
    "    # 3b. Create a lookup table for pmid to bwpid\n",
    "    pmid_to_bwpid_lookup = {pmid_for_wbpid['pm_id']: pmid_for_wbpid['wbp_id'] for pmid_for_wbpid in pmid_for_wbpid_list}\n",
    "    # 3c. Add PubMed Ids to the unique_references\n",
    "    for pmid_for_wbpid in pmid_for_wbpid_list:\n",
    "        wbp_id = pmid_for_wbpid['wbp_id']\n",
    "        unique_references[wbp_id]['pmid']= pmid_for_wbpid['pm_id']\n",
    "\n",
    "    # 4. Extract the pubmed ids into a list\n",
    "    pmid_list = [pmid_for_wbpid['pm_id'] for pmid_for_wbpid in pmid_for_wbpid_list]\n",
    "    \n",
    "    # 5. Post the list to ncbi entrez\n",
    "    ncbi_api = EntrezAPI()\n",
    "    entreze_epost_result = ncbi_api.entreze_epost(pmid_list)\n",
    "    \n",
    "    # 6. Fetch the full articles\n",
    "    if 'WebEnv' in entreze_epost_result:\n",
    "        # 6a. Link pubmed ids to pmcids\n",
    "        elink_result = ncbi_api.entreze_elink_pmid_to_pmcid(entreze_epost_result)\n",
    "        params= {'db': 'pmc'}\n",
    "        # 6b. post the pmcids\n",
    "        epost_result = ncbi_api.entreze_epost(elink_result, params)\n",
    "        # 6c. Fetch the articles based on the pmcids\n",
    "        efetch_result = ncbi_api.entreze_efetch(epost_result)\n",
    "        \n",
    "        # 6d. Write the content of the paper to a file\n",
    "        for article in efetch_result['articles']:\n",
    "            content = f\"Title:{article['title']}\\n\"\n",
    "            content += f\"Abstract: {article['abstract']}\\n\"\n",
    "            content += f\"Content: {article['body']}\\n\"\n",
    "            file_nm = f\"./output/PMC{article['pmcid']}.txt\"\n",
    "            with open(file_nm, 'w') as file:\n",
    "                file.write(content)\n",
    "            wbp_id = pmid_to_bwpid_lookup[article['pmid']]\n",
    "            unique_references[wbp_id]['pmcid'] = article['pmcid']\n",
    "            \n",
    "    \n",
    "    # #print(f\"unique_references {len(unique_references)}\")\n",
    "    #print(json.dumps(journal_articles, indent=4))\n",
    "    return unique_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_set = [\"WBGene00008850\",\"WBGene00001463\"]\n",
    "gene_set = [\"WBGene00016064\", \"WBGene00001463\", \"WBGene00001452\", \"WBGene00002048\", \"WBGene00003750\", \"WBGene00006575\", \"WBGene00006783\",\n",
    "            \"WBGene00019327\", \"WBGene00008850\", \"WBGene00019967\", \"WBGene00001452\", \"WBGene00001752\", \"WBGene00002048\", \"WBGene00003640\", \n",
    "            \"WBGene00007867\", \"WBGene00007875\", \"WBGene00008010\", \"WBGene00008584\", \"WBGene00008681\", \"WBGene00009429\", \"WBGene00016596\", \n",
    "            \"WBGene00019619\", \"WBGene00010290\", \"WBGene00000399\", \"WBGene00001430\", \"WBGene00010493\", \"WBGene00004512\", \"WBGene00004513\", \n",
    "            \"WBGene00004622\"]\n",
    "references_index = {}\n",
    "for wormbase_id in gene_set:\n",
    "    references_index = await get_references_wbid(wormbase_id, references_index)\n",
    "\n",
    "pmc_not_found(references_index)\n",
    "\n",
    "print(json.dumps(references_index, indent=4))\n",
    "with open(\"./output/references_index.json\", 'w') as file:\n",
    "    json.dump(references_index, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
